# Sección 02: Integrando Apache Camel con ActiveMQ y Kafka

---

## ¿Qué es Apache ActiveMQ?

`Apache ActiveMQ` es un broker de mensajes de código abierto que permite la comunicación asíncrona entre aplicaciones
o sistemas mediante el uso de mensajes. Es parte de la especificación `Java Message Service (JMS)`, por lo que es
compatible con aplicaciones basadas en JMS y otros protocolos de mensajería, como AMQP, MQTT, STOMP y WebSocket.

### Características principales de Apache ActiveMQ

1. `Mensajería asíncrona`: Permite el intercambio de mensajes sin la necesidad de que los sistemas estén directamente
   conectados o en tiempo real.
2. `Colas y temas (topics)`: `ActiveMQ` soporta tanto colas (donde cada mensaje se consume por un solo receptor) como
   temas (donde cada mensaje puede ser consumido por múltiples suscriptores).
3. `Persistencia de mensajes`: Ofrece almacenamiento persistente de mensajes, lo que permite la recuperación de mensajes
   en caso de fallos.
4. `Escalabilidad y distribución`: Puede configurarse en un clúster para balancear la carga y mejorar la disponibilidad.
5. `Compatibilidad con múltiples protocolos`: Admite varios protocolos de mensajería, lo que facilita su integración con
   diferentes sistemas y plataformas.

### Casos de uso

- `Microservicios`: Permite que los microservicios se comuniquen de forma asíncrona, mejorando la eficiencia y
  disponibilidad.
- `Integración de sistemas`: Ideal para conectar sistemas heterogéneos en una arquitectura orientada a eventos.
- `Procesamiento de eventos`: Facilita la implementación de patrones de diseño basados en eventos para procesar datos
  de forma eficiente.

`Apache ActiveMQ` es ampliamente utilizado en entornos empresariales donde se requiere una alta disponibilidad y
confiabilidad en el intercambio de mensajes.

## Crea contenedor de Apache ActiveMQ

Para continuar con nuestros ejemplos, en este apartado crearemos el contenedor de `Apache ActiveMQ` utilizando el
siguiente comando.

````bash
$ docker container run -d --name c-active-mq -p 61616:61616 -p 8161:8161 rmohr/activemq
````

Si listamos los contenedores veremos que nuestro contenedor de `ActiveMQ` se está ejecutando sin problemas.

````bash
$ docker container ls -a
CONTAINER ID   IMAGE                             COMMAND                  CREATED         STATUS                        PORTS                                                                                   NAMES
9915f722fa98   rmohr/activemq                    "/bin/sh -c 'bin/act…"   9 seconds ago   Up 9 seconds                  1883/tcp, 5672/tcp, 0.0.0.0:8161->8161/tcp, 61613-61614/tcp, 0.0.0.0:61616->61616/tcp   c-active-mq                                                                                            c-jenkins
````

Mediante el navegador vamos a la siguiente dirección `http://localhost:8161`.

![01.png](assets/01.png)

Ingresamos las credenciales `admin` y `admin`.

![02.png](assets/02.png)

Finalmente, vemos la pantalla principal luego de haber iniciado sesión exitosamente.

![03.png](assets/03.png)

## Creación de una ruta de Camel remitente para ActiveMQ en el camel-microservice-a

Como vamos a comunicarnos con `Apache ActiveMQ`, necesitamos agregar en el `pom.xml` del microservicio
`camel-microservice-a` la dependencia de `Apache Camel para ActiveMQ`.

````xml

<dependency>
    <groupId>org.apache.camel.springboot</groupId>
    <artifactId>camel-activemq-starter</artifactId>
    <version>4.8.1</version>
</dependency>
````

En seguida, agregamos la siguiente configuración en el `application.yml`. Recordemos que el puerto `61616` es el
puerto que definimos al crear el contenedor de `Apache ActiveMQ`.

````yml
spring:
  activemq:
    broker-url: tcp://localhost:61616
````

Finalmente, crearemos una clase llamada `ActiveMqSenderRoute` donde crearemos como fuente un temporizador que estará
enviando en intervalos regulares de 10 segundos un mensaje a la cola.

````java

@Component
public class ActiveMqSenderRoute extends RouteBuilder {
    @Override
    public void configure() throws Exception {
        from("timer:active-mq-timer?period=10000")
                .transform().constant("Mi mensaje para Active MQ")
                .log("${body}")
                .to("activemq:my-activemq-queue");
    }
}
````

Dentro del método `configure()`:

- `from("timer:active-mq-timer?period=10000")`: Configura una fuente de mensajes usando un temporizador. Este
  temporizador se activa cada 10 segundos (10000 milisegundos).
- `.transform().constant("Mi mensaje para Active MQ")`: Transforma cada mensaje generado por el temporizador en la
  cadena constante `"Mi mensaje para Active MQ"`.
- `.log("${body}")`: Registra el contenido del mensaje en los logs. La expresión `${body}` se usa para acceder al cuerpo
  del mensaje actual.
- `.to("activemq:my-activemq-queue")`: Envía el mensaje transformado a una cola de `ActiveMQ` llamada
  `my-activemq-queue`.

En resumen, esta ruta en `Camel` se activa cada 10 segundos, genera un mensaje constante, lo registra y luego lo envía a
una cola en `ActiveMQ`.

Al ejecutar la aplicación veremos en consola que cada 10 segundos se está enviando a la cola el siguiente mensaje.

````bash
[camel-microservice-a] [active-mq-timer] route1                                   : Mi mensaje para Active MQ
````

Si observamos en la web la cola del `ActiveMQ`, veremos que los mensajes se están acumulando cada 10 segundos. En la
imagen observamos la cola `my-activemq-queue` que al momento de capturar la imagen tiene `11` mensajes en cola.

![01.png](assets/seccion-02/01.png)

## Creación de una ruta de Camel receptor para ActiveMQ en el camel-microservice-b

Recordemos que en el apartado anterior creamos en el microservicio `camel-microservice-a` una clase llamada
`ActiveMqSenderRoute` donde configuramos la ruta para poder enviar información a la cola de `ActiveMQ`.

En este apartado, trabajaremos con el microservicio `camel-microservice-b`, donde crearemos una clase llamada
`ActiveMqReceiverRoute` que nos permitirá procesar la información que obtenga de la cola de `ActiveMQ`.

Empezaremos agregando la dependencia de `Camel` con la integración de `ActiveMQ` en nuestro microservicio
`camel-microservice-b`.

````xml

<dependency>
    <groupId>org.apache.camel.springboot</groupId>
    <artifactId>camel-activemq-starter</artifactId>
    <version>4.8.1</version>
</dependency>
````

También agregaremos las siguientes configuraciones en el `application.yml`.

````yml
server:
  port: 8000
  error:
    include-message: always

spring:
  application:
    name: camel-microservice-b

  activemq:
    broker-url: tcp://localhost:61616
````

Ahora procedemos a crear la clase `ActiveMqReceiverRoute` donde configuraremos una ruta de camel para poder consumir la
información desde `ActiveMQ`.

````java

@Component
public class ActiveMqReceiverRoute extends RouteBuilder {
    @Override
    public void configure() throws Exception {
        from("activemq:my-activemq-queue")
                .to("log:received-message-from-active-mq");
    }
}
````

Recordemos que en el microservicio `camel-microservice-a` estamos enviando información a la cola de `ActiveMQ` de esta
manera `.to("activemq:my-activemq-queue")`, por lo que, ahora en este microservicio `camel-microservice-b` necesitamos
consumir dicha cola `(my-activemq-queue)`, así que eso es lo que pondremos en el `from()`. Ahora, la información que
consumamos simplemente lo vamos a imprimir en consola.

Si ejecutamos la aplicación veremos en consola, en primer lugar la cantidad de mensajes acumulados en la cola del
`ActiveMQ`, eso es porque en el apartado anterior habíamos trabajado con el microservicio que enviaba mensajes a la
cola y no había quién lo consuma. Entonces, ahora nuestra aplicación `camel-microservice-b` está consumiéndolos, luego
cada 10 segundos irá consumiendo lo que se publique en la cola del `ActiveMQ`.

````bash
[camel-microservice-b] [activemq-queue]] received-message-from-active-mq          : Exchange[ExchangePattern: InOnly, BodyType: String, Body: Mi mensaje para Active MQ]
[camel-microservice-b] [activemq-queue]] received-message-from-active-mq          : Exchange[ExchangePattern: InOnly, BodyType: String, Body: Mi mensaje para Active MQ]
[camel-microservice-b] [activemq-queue]] received-message-from-active-mq          : Exchange[ExchangePattern: InOnly, BodyType: String, Body: Mi mensaje para Active MQ]
[camel-microservice-b] [activemq-queue]] received-message-from-active-mq          : Exchange[ExchangePattern: InOnly, BodyType: String, Body: Mi mensaje para Active MQ]
[camel-microservice-b] [activemq-queue]] received-message-from-active-mq          : Exchange[ExchangePattern: InOnly, BodyType: String, Body: Mi mensaje para Active MQ]
[camel-microservice-b] [activemq-queue]] received-message-from-active-mq          : Exchange[ExchangePattern: InOnly, BodyType: String, Body: Mi mensaje para Active MQ]
...
````

Ahora, si entramos en la web del `ActiveMQ` y revisamos nuestra cola `my-activemq-queue` veremos que no tendremos
mensajes pendientes, ya que nuestro consumidor está trabajando correctamente.

![02.png](assets/seccion-02/02.png)

## Comprendiendo la terminología y arquitectura de Camel

- `Camel Context`: (0..n) Routes + Components + ...
    - `Endpoint`, reference to a queue, database or a file
    - `Route`, endpoints + processor(s) + transformer(s)
    - `Components`, extensions (Kafka, JSON, JMS, etc)
    - `Transformation`:
        - Data format transformation - XML to JSON
        - Data type transformation - String to CurrencyConversionBean
- `Message`, Body + Headers + Attachments
- `Exchange`, Request + Response
    - Exchange ID
    - Message Exchange Pattern (MEP) - InOnly/InOut
    - Input Message and (Optional) Output Message

![03.png](assets/seccion-02/03.png)

`CamelContext` es el sistema de ejecución que reúne todos los conceptos fundamentales de `Apache Camel` (rutas, puntos
finales, componentes, etc.).

Este objeto de contexto representa el sistema de ejecución de Camel. Normalmente, hay una instancia de `CamelContext`
en una aplicación.

![04.png](assets/seccion-02/04.png)

`CamelContext` proporciona acceso a muchas funciones y servicios, entre los que destacan componentes, conversores de
tipos, un registro, puntos finales, rutas, formatos de datos e idiomas.

En `Apache Camel`, el `Camel Context` es el corazón de cualquier aplicación `Camel`, especialmente cuando se usa en
conjunto con Spring Boot. El `Camel Context` actúa como el entorno donde se configuran y gestionan todas las rutas,
componentes, endpoints y otras configuraciones necesarias para el flujo de integración.

### ¿Qué es el Camel Context?

El `Camel Context` es como un contenedor o motor central que maneja y ejecuta las rutas de Camel, donde define la lógica
y el flujo de los datos que pasan por la aplicación. En términos simples, es donde "vive" la configuración de Camel, y
es responsable de las siguientes funciones clave:

1. `Gestión de rutas`: El `Camel Context` administra las rutas, que son secuencias de instrucciones que determinan cómo
   los mensajes fluyen a través de los endpoints.
2. `Instanciación y gestión de componentes`: Cada componente (como File, JMS, FTP, SFTP, etc.) se registra en el Camel
   Context. Esto permite que las rutas accedan a estos componentes mediante URIs específicos.
3. `Gestión de endpoints`: Un `endpoint` es un punto de `entrada` o `salida` para el flujo de datos en una ruta de
   Camel. El Camel Context se asegura de que los endpoints se gestionen adecuadamente.
4. `Intercepción y monitoreo de mensajes`: Proporciona una capa donde puedes agregar interceptores para monitorear o
   modificar mensajes en el flujo.

### Componentes del Camel Context

Algunos de los elementos más importantes que maneja el `Camel Context` incluyen:

- `Endpoints`: Son puntos de comunicación en Camel. Un endpoint puede ser cualquier cosa que envíe o reciba mensajes,
  como un archivo, una cola de mensajes, un servicio HTTP, etc. Cada endpoint se define usando un URI específico del
  componente (por ejemplo, `file:input` o `jms:queue:myQueue`).


- `Routes`: Las rutas (routes) son secuencias de instrucciones en Camel que definen el flujo de un mensaje. Cada ruta
  comienza con un endpoint de origen y luego pasa por varios pasos, como transformaciones, filtros y otras lógicas de
  procesamiento, hasta llegar a un endpoint de destino.


- `Componentes`: Son "conectores" reutilizables que permiten que Camel se conecte a diferentes sistemas, protocolos o
  tecnologías, como bases de datos, FTP, APIs REST, etc. Los componentes definen los tipos de endpoints que puedes usar
  y se cargan en el Camel Context automáticamente al iniciar la aplicación.

## Desagrupación (unmashalling) de mensajes JSON en Java Bean en Camel Route de ActiveMQ

En los apartados anteriores habíamos creado en nuestros microservicios uno que envíaba mensaje a la cola de `ActiveMQ`
y el otro microservicio era quien lo consumía. En este apartado, enviaremos como mensaje a la cola de `ActiveMQ` un
archivo `JSON` y será el otro microservicio quien consuma ese JSON y lo convierta a un objeto java.

En el microservicio `camel-microservice-a`, al colocar un archivo `.json` en el directorio `/json` automáticamente se
envía a la cola `my-activemq-queue` del `ActiveMQ` y el archivo se guarda dentro del `/json/.camel`. Luego, como tenemos
definido el `.log("${body}") en la ruta de camel, vemos que se muestra en el log el contenido enviado.

### En el camel-microservice-a

Empezaremos creando un directorio en la raíz de este proyecto `/files/json`. En este directorio colocaremos el archivo
`.json` que enviaremos a la cola de `ActiveMQ`.

````bash
/files/json
````

Ahora, modificamos la clase `ActiveMqSenderRoute` para poder enviar archivos json a la cola `my-activemq-queue` del
`ActiveMQ`.

````java

@Component
public class ActiveMqSenderRoute extends RouteBuilder {
    @Override
    public void configure() throws Exception {
        from("file:files/json")
                .log("${body}")
                .to("activemq:my-activemq-queue");
    }
}
````

Notar que como origen o fuente de datos estamos definiendo la ruta que creamos anteriormente `files/json` y como
destino, estamos definiendo la cola `my-activemq-queue` del `ActiveMQ`.

Cuando coloquemos algún archivo `.json` en el directorio `files/json` veremos en consola de este microservicio el
siguiente resultado, esto es gracias al `.log("${body}")`.

````bash
[camel-microservice-a] [le://files/json] route1                                   : {
  "id": 1000,
  "from": "USD",
  "to": "INR",
  "conversionMultiple": 70
}
````

### En el camel-microservice-b

Iniciamos agregando la dependencia de Jackson integrada a Camel ya que lo usaremos para convertir un objeto json a su
correspondiente objeto java.

````xml

<dependency>
    <groupId>org.apache.camel.springboot</groupId>
    <artifactId>camel-jackson-starter</artifactId>
    <version>4.8.1</version>
</dependency>
````

A continuación, vamos a crear una clase de modelo llamado `CurrencyExchange`. Esta clase es una especie dto o pojo que
contiene los atributos idénticos del json que se recepcionará.

````java

@ToString
@AllArgsConstructor
@NoArgsConstructor
@Builder
@Getter
@Setter
public class CurrencyExchange {
    private Long id;
    private String from;
    private String to;
    private BigDecimal conversionMultiple;
}
````

Realizamos algunas modificaciones a la clase `ActiveMqReceiverRoute` donde vamos a hacer la conversión `(unmarshal)`
del `json` obtenido de la cola `my-activemq-queue` a un objeto java que será del tipo `CurrencyExchange`.

````java

@Component
public class ActiveMqReceiverRoute extends RouteBuilder {

    @Override
    public void configure() throws Exception {
        from("activemq:my-activemq-queue")
                .unmarshal().json(JsonLibrary.Jackson, CurrencyExchange.class)
                .to("log:received-message-from-active-mq");
    }
}
````

Luego de ejecutar la aplicación vemos el siguiente log mostrado en consola, donde vemos que efectivamente se está
realizando la conversión del json consumido al tipo `BodyType: dev.magadiflo.app.models.CurrencyExchange`.

````bash
[camel-microservice-b] [activemq-queue]] received-message-from-active-mq          : Exchange[ExchangePattern: InOnly, BodyType: dev.magadiflo.app.models.CurrencyExchange, Body: CurrencyExchange(id=1000, from=USD, to=INR, conversionMultiple=70)]
````

## Transformación y procesamiento después de la desagrupación (unmashalling) en Camel Route

### Procesamiento

Supongamos que, luego de que agreguemos un archivo `json` al directorio `/files/json`, nuestro microservicio
`camel-microservice-b` necesita realizar algún procesamiento antes de enviar el mensaje al endpoint de destino.
Para eso, vamos a agregar un `bean` que nos permitirá procesar el mensaje que se obtiene de la cola
`my-activemq-queue`.

````java

@Slf4j
@RequiredArgsConstructor
@Component
public class ActiveMqReceiverRoute extends RouteBuilder {

    private final MyCurrencyExchangeProcessor myCurrencyExchangeProcessor;

    @Override
    public void configure() throws Exception {
        from("activemq:my-activemq-queue")
                .unmarshal().json(JsonLibrary.Jackson, CurrencyExchange.class)
                .bean(this.myCurrencyExchangeProcessor)
                .to("log:received-message-from-active-mq");
    }
}

@Slf4j
@Component
class MyCurrencyExchangeProcessor {

    public void processMessage(CurrencyExchange currencyExchange) {
        log.info("Realiza procesamiento con currencyExchange.getConversionMultiple() cuyo valor es {}", currencyExchange.getConversionMultiple());
    }

}
````

Como se observa en el código anterior, se ha creado una clase de componente que define un método cuyo parámetro recibe
un objeto (`CurrencyExchange`) del tipo de dato que vamos a procesar. En este caso será el objeto del tipo
`CurrencyExchange`, dado que en la ruta `camel` hemos realizado el `unmarshal()` del `json` recibido desde la cola
`my-activemq-queue`. Por lo tanto, el bean que crearemos lo colocaremos a continuación del `unmarshal()` realizado.

Ahora, simplemente levantamos el contenedor del `ActiveMQ`, levantamos el `camel-microservice-a` y finalmente el
`camel-microservice-b`. Cogemos el mismo archivo `.json` que estamos usando para las pruebas y lo colocamos en el
directorio `/files/json`.

Solo porsiacaso el archivo se llama `1000.json` y su contenido es.

````json
{
  "id": 1000,
  "from": "USD",
  "to": "INR",
  "conversionMultiple": 70
}
````

Luego de haber colocado el archivo en el directorio `/files/json`, vemos el siguiente resultado en consola.

- `camel-microservice-a`

````bash
2024-11-10T13:08:13.212-05:00  INFO 18316 --- [camel-microservice-a] [le://files/json] route1                                   : {
  "id": 1000,
  "from": "USD",
  "to": "INR",
  "conversionMultiple": 70
}
````

- `camel-microservice-b`

````bash
2024-11-10T13:08:13.872-05:00  INFO 7056 --- [camel-microservice-b] [activemq-queue]] d.m.a.r.MyCurrencyExchangeProcessor      : Realiza procesamiento con currencyExchange.getConversionMultiple() cuyo valor es 70
2024-11-10T13:08:13.874-05:00  INFO 7056 --- [camel-microservice-b] [activemq-queue]] received-message-from-active-mq          : Exchange[ExchangePattern: InOnly, BodyType: dev.magadiflo.app.models.CurrencyExchange, Body: CurrencyExchange(id=1000, from=USD, to=INR, conversionMultiple=70)]
````

En este último log, observemos que el primer resultado corresponde al mensaje que estamos imprimiendo por consola en el
método `processMessage(CurrencyExchange currencyExchange)`. Ahora, si observamos el directorio `/files/json` veremos
que el archivo `1000.json` fue trasladado al directorio oculto `.camel`.

### Procesamiento

En el apartado anterior, simplemente hemos procesado el mensaje, es decir, lo hemos escrito por consola, no hemos
modificado el cuerpo del mensaje. Pero qué pasa si quisiéramos modificarlo, `¿cómo lo haríamos?`.

Para eso, crearemos un nuevo `bean` que se encargará de modificar cada dato obtenido y luego retornar el objeto
modificado. En el siguiente código se observa dicha implementación.

````java

@Slf4j
@RequiredArgsConstructor
@Component
public class ActiveMqReceiverRoute extends RouteBuilder {

    private final MyCurrencyExchangeProcessor myCurrencyExchangeProcessor;
    private final MyCurrencyExchangeTransformer myCurrencyExchangeTransformer;

    @Override
    public void configure() throws Exception {
        from("activemq:my-activemq-queue")
                .unmarshal().json(JsonLibrary.Jackson, CurrencyExchange.class)
                .bean(this.myCurrencyExchangeProcessor)
                .bean(this.myCurrencyExchangeTransformer)
                .to("log:received-message-from-active-mq");
    }
}

@Slf4j
@Component
class MyCurrencyExchangeProcessor {

    public void processMessage(CurrencyExchange currencyExchange) {
        log.info("Realiza procesamiento con currencyExchange.getConversionMultiple() cuyo valor es {}", currencyExchange.getConversionMultiple());
    }

}

@Slf4j
@Component
class MyCurrencyExchangeTransformer {

    public CurrencyExchange processMessage(CurrencyExchange currencyExchange) {
        BigDecimal multiply = currencyExchange.getConversionMultiple().multiply(BigDecimal.TEN);
        currencyExchange.setConversionMultiple(multiply);
        return currencyExchange;
    }
}
````

Ahora, si ejecutamos la aplicación: `contenedor de ActiveMQ + camel-microservice-a + camel-microservice-b` y colocamos
el archivo `1000.json` en el directorio `/files/json`, veremos el siguiente resultado en la consola del microservicio
`camel-microservice-b`.

````bash
2024-11-10T13:23:10.622-05:00  INFO 7652 --- [camel-microservice-b] [activemq-queue]] d.m.a.r.MyCurrencyExchangeProcessor      : Realiza procesamiento con currencyExchange.getConversionMultiple() cuyo valor es 70
2024-11-10T13:23:10.625-05:00  INFO 7652 --- [camel-microservice-b] [activemq-queue]] received-message-from-active-mq          : Exchange[ExchangePattern: InOnly, BodyType: dev.magadiflo.app.models.CurrencyExchange, Body: CurrencyExchange(id=1000, from=USD, to=INR, conversionMultiple=700)]
````

Como observamos, la transformación se ha realizado con éxito, dado que el valor inicial de `70` de la propiedad
`conversionMultiple` ha sido multiplada por `10` en nuestro método de transformación y como resultado obtenemos `700`
en el log final.

## Desagrupación (unmarshalling) de mensajes XML en Java Bean en Camel Route de ActiveMQ

En el apartado anterior estuvimos trabajando con archivos `json`, donde cargábamos un archivo `json` al directorio
`/files/json` y en automático el microservicio `camel-microservice-a` procesaba el archivo enviándolo a la cola de
`ActiveMQ` `my-activemq-queue`. Luego, nuestro microservicio `camel-microservice-b` consumía el `json` de la cola
mostrándolo en consola.

### Envía mensajes XML a la cola del ActiveMQ

En este apartado haremos algo similar, pero trabajando con archivos `xml`. Así que el primero paso será crear un
directorio en el `/files/xml` donde agregaremos los archivos en ese formato.

Como siguiente paso, en el `camel-microservice-a` vamos a crear una nueva clase de componente llamado
`ActiveMqXmlSenderRoute`. Ahora, para tener únicamente a este componente ejecutándose desde el inicio vamos a tener que
comentar la anotación `@Component` de la clase `ActiveMqSenderRoute`, que es con la que trabajámos anteriormente para
los archivos `json`. Haciendo esto, tendremos únicamente nuestra clase `ActiveMqXmlSenderRoute` en ejecución.

Ahora, implementaremos nuestra clase de componente para enviar archivos `xml` a la cola de `ActiveMQ`. La cola a la que
enviaremos se llamará `my-activemq-xml-queue`.

````java

@Component
public class ActiveMqXmlSenderRoute extends RouteBuilder {
    @Override
    public void configure() throws Exception {
        from("file:files/xml")
                .log("${body}")
                .to("activemq:my-activemq-xml-queue");
    }
}
````

Ahora, procedemos a colocar un archivo `xml` en el directorio `/files/xml`. El archivo que colocaremos es el archivo
`1002.xml` cuyo contenido es el siguiente.

````xml
<?xml version="1.0" encoding="UTF-8"?>
<root>
    <id>1002</id>
    <from>AUD</from>
    <to>INR</to>
    <conversionMultiple>10</conversionMultiple>
</root>
````

A continuación, nuestra aplicación `camel-microservice-a` procesará dicho archivo y lo enviará a la cola, siendo lo
siguiente lo que se mostrará en consola.

````bash
2024-11-10T19:25:44.819-05:00  INFO 14064 --- [camel-microservice-a] [ile://files/xml] route1                                   : <?xml version="1.0" encoding="UTF-8"?>
<root>
   <id>1002</id>
   <from>AUD</from>
   <to>INR</to>
   <conversionMultiple>10</conversionMultiple>
</root>
````

Si revisamos la web del `ActiveMQ` veremos que tenemos 1 mensaje pendiente y 0 número de consumidores.

![05.png](assets/seccion-02/05.png)

### Consume mensaje xml de la cola deL ActiveMQ

En este apartado trabajaremos sobre el microservicio `camel-microservice-b`, en la clase `ActiveMqReceiverRoute`,
simplemente la modificaremos para no estar creando otra clase.

Antes de realizar la implementación completa, únicamente vamos a modificar el `from()` desde donde vamos a consumir y
dejar el `to()` para ver lo que se muestra en consola, lo demás lo vamos a comentar.

````java

@Slf4j
@RequiredArgsConstructor
@Component
public class ActiveMqReceiverRoute extends RouteBuilder {

    private final MyCurrencyExchangeProcessor myCurrencyExchangeProcessor;
    private final MyCurrencyExchangeTransformer myCurrencyExchangeTransformer;

    @Override
    public void configure() throws Exception {
        from("activemq:my-activemq-xml-queue")
//                .unmarshal().json(JsonLibrary.Jackson, CurrencyExchange.class)
//                .bean(this.myCurrencyExchangeProcessor)
//                .bean(this.myCurrencyExchangeTransformer)
                .to("log:received-message-from-active-mq");
    }
}
````

Como resultado, vemos que está consumiendo de la cola `my-activemq-xml-queue` donde anteriormente subimos el archivo
`xml`. Entonces, con esto nos aseguramos de que efectivamente lo que se está consumiendo es un xml, por lo que
toca realizar la conversión a un objeto java.

````bash
2024-11-10T19:44:02.832-05:00  INFO 11632 --- [camel-microservice-b] [vemq-xml-queue]] received-message-from-active-mq          : Exchange[ExchangePattern: InOnly, BodyType: byte[], Body: <?xml version="1.0" encoding="UTF-8"?>
<root>
   <id>1002</id>
   <from>AUD</from>
   <to>INR</to>
   <conversionMultiple>10</conversionMultiple>
</root>]
````

### Convierte mensaje consumido xml en objeto java

En el microservice `camel-microservice-b` estamos consumiendo los mensajes en `xml` que se han subido a la cola
`my-activemq-xml-queue`. Ahora, necesitamos convertir el mensaje `xml` en un objeto java, por lo que necesitamos
agregar en el `pom.xml` de este microservicio la dependencia que nos ayudará a realizar esa conversión.

````xml

<dependency>
    <groupId>org.apache.camel.springboot</groupId>
    <artifactId>camel-jacksonxml-starter</artifactId>
    <version>4.8.1</version>
</dependency>
````

Luego, procedemos a implementar la clase `ActiveMqReceiverRoute`, donde hacemos el `unmarshall()` del `xml` hacia un
objeto java tal como se muestra a continuacón.

````java

@Slf4j
@RequiredArgsConstructor
@Component
public class ActiveMqReceiverRoute extends RouteBuilder {
    @Override
    public void configure() throws Exception {
        from("activemq:my-activemq-xml-queue")
                .unmarshal().jacksonXml(CurrencyExchange.class)
                .to("log:received-message-from-active-mq");
    }
}
````

Finalmente, teniendo todos nuestros servicios levantados, colocamos el archivo xml en el directorio `/files/xml`. El
mensaje se enviará a la cola del `ActiveMQ` y nuestro `camel-microservice-b` lo consumirá realizando la conversión
a un objeto java. La conversión realizada se envía al log definido en el `.to()`, donde vemos que efectivamente
se ha convertido el mensaje a un objeto java que es del tipo de la clase `CurrencyExchange`.

````bash
2024-11-10T19:53:35.911-05:00  INFO 5544 --- [camel-microservice-b] [vemq-xml-queue]] received-message-from-active-mq          : Exchange[ExchangePattern: InOnly, BodyType: dev.magadiflo.app.models.CurrencyExchange, Body: CurrencyExchange(id=1002, from=AUD, to=INR, conversionMultiple=10)]
````

## Enviar y recibir mensajes en Kafka con Camel

Lo primero que haremos será crear el archivo `compose.yml` en la raíz de este proyecto con los servicios de
`zookeeper` y `kafka`.

````yml
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: c-zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: [ "CMD-SHELL", "nc -z localhost 2181 || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: c-kafka
    restart: unless-stopped
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    ports:
      - '9092:9092'
    depends_on:
      zookeeper:
        condition: service_healthy
````

Para levantar los contenedores, nos posicionamos en la raíz donde se encuentra el archivo `compose.yml` y ejecutamos el
siguiente comando.

````bash
M:\PERSONAL\PROGRAMACION\DESARROLLO_JAVA_SPRING\01.udemy\04.in28Minutes_Official\apache-camel-projects (main -> origin)
$ docker compose up -d                           
[+] Running 3/3                                  
 ✔ Network apache-camel-projects_default  Created
 ✔ Container c-zookeeper                  Healthy
 ✔ Container c-kafka                      Started
````

Si listamos los contenedores veremos que nuestros servicios están ejecutándose correctamente.

````bash
$ docker container ls -a
CONTAINER ID   IMAGE                             COMMAND                  CREATED         STATUS                     PORTS                          NAMES
91d3ca91e37e   confluentinc/cp-kafka:7.4.0       "/etc/confluent/dock…"   2 minutes ago   Up About a minute          0.0.0.0:9092->9092/tcp         c-kafka
4d4cd78ff95e   confluentinc/cp-zookeeper:7.4.0   "/etc/confluent/dock…"   2 minutes ago   Up 2 minutes (healthy)     2181/tcp, 2888/tcp, 3888/tcp   c-zookeeper
````

A continuación agregamos la siguiente dependencia al `pom.xml` del `camel-microservice-a` y del `camel-microservice-b`.
Esta dependencia nos permitirá integrar kafka con camel.

````xml

<dependency>
    <groupId>org.apache.camel.springboot</groupId>
    <artifactId>camel-kafka-starter</artifactId>
    <version>4.8.1</version>
</dependency>
````

Luego, en el `application.yml` de ambos microservicios agregamos la siguiente configuración. Notar que estamos apuntando
a la url de kafka.

````yml
camel:
  component:
    kafka:
      brokers: http://localhost:9092
````

### En el camel-microsrevice-a

Creamos una nueva clase de componente `KafkaSenderRoute` y agregamos el siguiente código.

````java

@Component
public class KafkaSenderRoute extends RouteBuilder {
    @Override
    public void configure() throws Exception {
        from("file:files/json")
                .log("${body}")
                .to("kafka:my-kafka-topic");
    }
}
````

Notar que al topic a donde enviaremos los mensajes será llamado `my-kafka-topic`.

**Nota***
> Anteriormente, habíamos estado trabajando con la clase `ActiveMqXmlSenderRoute`, por lo que vamos a comentar su
> anotación `@Component`, para trabajar únicamente con este nuevo componente `KafkaSenderRoute`.

Ejecutamos este microservicio y en el log vemos parte del siguiente log.

````bash
[camel-microservice-a] [           main] d.m.app.CamelMicroserviceAApplication    : No active profile set, falling back to 1 default profile: "default"
[camel-microservice-a] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port 8080 (http)
[camel-microservice-a] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
[camel-microservice-a] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.31]
[camel-microservice-a] [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
[camel-microservice-a] [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 4248 ms
[camel-microservice-a] [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 1 endpoint beneath base path '/actuator'
[camel-microservice-a] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port 8080 (http) with context path '/'
[camel-microservice-a] [           main] o.a.c.impl.engine.AbstractCamelContext   : Apache Camel 4.8.1 (camel-1) is starting
[camel-microservice-a] [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [http://localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[camel-microservice-a] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
[camel-microservice-a] [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
[camel-microservice-a] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.7.1
[camel-microservice-a] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e2494e6ffb89f828
[camel-microservice-a] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1731383965673
[camel-microservice-a] [           main] o.a.c.impl.engine.AbstractCamelContext   : Routes startup (total:1)
[camel-microservice-a] [           main] o.a.c.impl.engine.AbstractCamelContext   :     Started route1 (file://files/json)
[camel-microservice-a] [           main] o.a.c.impl.engine.AbstractCamelContext   : Apache Camel 4.8.1 (camel-1) started in 674ms (build:0ms init:0ms start:674ms)
[camel-microservice-a] [           main] d.m.app.CamelMicroserviceAApplication    : Started CamelMicroserviceAApplication in 10.394 seconds (process running for 12.778)
[camel-microservice-a] [ad | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: 7-v0DYKXTpGSzkvm7rgxGw
[camel-microservice-a] [ad | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 0 with epoch 0
````

### En el camel-microsrevice-b

Creamos una nueva clase de componente que recibirá los mensajes que se envíen al topic `my-kafka-topic` de `kafka`.

````java

@Component
public class KafkaReceiverRoute extends RouteBuilder {
    @Override
    public void configure() throws Exception {
        from("kafka:my-kafka-topic")
                .to("log:received-message-from-kafka");
    }
}
````

Si levantamos este microservicio, debemos observar en consola el siguiente resultado.

````bash
[camel-microservice-b] [           main] d.m.app.CamelMicroserviceBApplication    : No active profile set, falling back to 1 default profile: "default"
[camel-microservice-b] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port 8000 (http)
[camel-microservice-b] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
[camel-microservice-b] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.31]
[camel-microservice-b] [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
[camel-microservice-b] [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 4085 ms
[camel-microservice-b] [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 1 endpoint beneath base path '/actuator'
[camel-microservice-b] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port 8000 (http) with context path '/'
[camel-microservice-b] [           main] o.a.c.impl.engine.AbstractCamelContext   : Apache Camel 4.8.1 (camel-1) is starting
[camel-microservice-b] [           main] o.a.camel.component.kafka.KafkaConsumer  : Starting Kafka consumer on topic: my-kafka-topic with breakOnFirstError: false
[camel-microservice-b] [my-kafka-topic]] o.a.c.component.kafka.KafkaFetchRecords  : Connecting Kafka consumer thread ID my-kafka-topic-Thread 0 with poll timeout of 5000 ms
[camel-microservice-b] [my-kafka-topic]] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [http://localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2365ff20-f911-43c7-884d-391fc920c3a8
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[camel-microservice-b] [           main] o.a.c.impl.engine.AbstractCamelContext   : Routes startup (total:2)
[camel-microservice-b] [           main] o.a.c.impl.engine.AbstractCamelContext   :     Started route1 (activemq://my-activemq-xml-queue)
[camel-microservice-b] [           main] o.a.c.impl.engine.AbstractCamelContext   :     Started route2 (kafka://my-kafka-topic)
[camel-microservice-b] [           main] o.a.c.impl.engine.AbstractCamelContext   : Apache Camel 4.8.1 (camel-1) started in 616ms (build:0ms init:0ms start:616ms)
[camel-microservice-b] [           main] d.m.app.CamelMicroserviceBApplication    : Started CamelMicroserviceBApplication in 10.121 seconds (process running for 11.144)
[camel-microservice-b] [my-kafka-topic]] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
[camel-microservice-b] [my-kafka-topic]] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.7.1
[camel-microservice-b] [my-kafka-topic]] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: e2494e6ffb89f828
[camel-microservice-b] [my-kafka-topic]] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1731384645853
[camel-microservice-b] [my-kafka-topic]] o.a.c.c.k.c.s.c.AssignmentAdapterHelper  : Using NO-OP resume strategy
[camel-microservice-b] [my-kafka-topic]] o.a.c.component.kafka.KafkaFetchRecords  : Searching for a custom subscribe adapter on the registry
[camel-microservice-b] [my-kafka-topic]] o.a.c.c.k.c.s.s.DefaultSubscribeAdapter  : Subscribing to topic(s) my-kafka-topic
[camel-microservice-b] [my-kafka-topic]] o.a.k.c.c.internals.LegacyKafkaConsumer  : [Consumer clientId=consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1, groupId=2365ff20-f911-43c7-884d-391fc920c3a8] Subscribed to topic(s): my-kafka-topic
[camel-microservice-b] [my-kafka-topic]] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1, groupId=2365ff20-f911-43c7-884d-391fc920c3a8] Cluster ID: 7-v0DYKXTpGSzkvm7rgxGw
[camel-microservice-b] [my-kafka-topic]] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1, groupId=2365ff20-f911-43c7-884d-391fc920c3a8] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
[camel-microservice-b] [my-kafka-topic]] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1, groupId=2365ff20-f911-43c7-884d-391fc920c3a8] (Re-)joining group
[camel-microservice-b] [my-kafka-topic]] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1, groupId=2365ff20-f911-43c7-884d-391fc920c3a8] Request joining group due to: need to re-join with the given member-id: consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1-85dd6cef-e27e-458f-9602-7ae5cac324e2
[camel-microservice-b] [my-kafka-topic]] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1, groupId=2365ff20-f911-43c7-884d-391fc920c3a8] (Re-)joining group
[camel-microservice-b] [my-kafka-topic]] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1, groupId=2365ff20-f911-43c7-884d-391fc920c3a8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1-85dd6cef-e27e-458f-9602-7ae5cac324e2', protocol='range'}
[camel-microservice-b] [my-kafka-topic]] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1, groupId=2365ff20-f911-43c7-884d-391fc920c3a8] Finished assignment for group at generation 1: {consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1-85dd6cef-e27e-458f-9602-7ae5cac324e2=Assignment(partitions=[my-kafka-topic-0])}
[camel-microservice-b] [my-kafka-topic]] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1, groupId=2365ff20-f911-43c7-884d-391fc920c3a8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1-85dd6cef-e27e-458f-9602-7ae5cac324e2', protocol='range'}
[camel-microservice-b] [my-kafka-topic]] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1, groupId=2365ff20-f911-43c7-884d-391fc920c3a8] Notifying assignor about the new Assignment(partitions=[my-kafka-topic-0])
[camel-microservice-b] [my-kafka-topic]] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1, groupId=2365ff20-f911-43c7-884d-391fc920c3a8] Adding newly assigned partitions: my-kafka-topic-0
[camel-microservice-b] [my-kafka-topic]] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1, groupId=2365ff20-f911-43c7-884d-391fc920c3a8] Found no committed offset for partition my-kafka-topic-0
[camel-microservice-b] [my-kafka-topic]] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-2365ff20-f911-43c7-884d-391fc920c3a8-1, groupId=2365ff20-f911-43c7-884d-391fc920c3a8] Resetting offset for partition my-kafka-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1001 rack: null)], epoch=0}}.
````

## Probando el envío y recepción de mensajes en Kafka con Camel

Teniendo nuestros dos microservicios levantados, vamos a pegar el archivo `1002.json` en el directorio `/files/json`.
El archivo tiene el siguiente contenido.

````json
{
  "id": 1002,
  "from": "AUD",
  "to": "INR",
  "conversionMultiple": 10
}
````

Como resultado, en el log del `camel-microservice-a` vemos el siguiente resultado.

````bash
2024-11-11T23:16:03.455-05:00  INFO 14164 --- [camel-microservice-a] [le://files/json] route1                                   : {
  "id": 1002,
  "from": "AUD",
  "to": "INR",
  "conversionMultiple": 10
}
````

Mientras que en el log del `camel-microservice-b` vemos el siguiente resultado.

````bash
2024-11-11T23:16:03.720-05:00  INFO 21500 --- [camel-microservice-b] [my-kafka-topic]] received-message-from-kafka              : Exchange[ExchangePattern: InOnly, BodyType: String, Body: {
  "id": 1002,
  "from": "AUD",
  "to": "INR",
  "conversionMultiple": 10
}]
````

Com observamos en los logs de ambos microservicios, se está enviando el archivo `1002.json` gracias al primer
microservicio, mientras que el segundo se encarga de recepcionarlo desde el tópico `my-kafka-topic` de `kafka`.